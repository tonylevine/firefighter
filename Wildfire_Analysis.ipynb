{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec2e6b5-46a1-4a4a-9f7b-23cc64832887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from rtree import index\n",
    "from datetime import datetime, timedelta\n",
    "import contextily as ctx\n",
    "import folium\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022b4ea5-1554-48ee-a692-7dc8df83aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "from functools import partial\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add7917d-99b8-43cd-9b5a-ea7666e76779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "path = r'/media/scruffy/Elements/python_data/Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "118fc6e4-5256-4f60-bda5-42777cf50d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load climate variables as DataFrames\n",
    "df2015 = pd.read_csv(os.path.join(path, 'era5_2015.csv'))\n",
    "df2016 = pd.read_csv(os.path.join(path, 'era5_2016.csv'))\n",
    "df2017 = pd.read_csv(os.path.join(path, 'era5_2017.csv'))\n",
    "df2018 = pd.read_csv(os.path.join(path, 'era5_2018.csv'))\n",
    "df2019 = pd.read_csv(os.path.join(path, 'era5_2019.csv'))\n",
    "df2020 = pd.read_csv(os.path.join(path, 'era5_2020.csv'))\n",
    "df2021 = pd.read_csv(os.path.join(path, 'era5_2021.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "13788fe2-eefd-4aed-8d42-653017c72295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_geodataframes(dataframes_dict):\n",
    "\n",
    "    geo_dataframes = {}\n",
    "    \n",
    "    for name, df in dataframes_dict.items():\n",
    "        # Create point geometries\n",
    "        geometry = gpd.points_from_xy(df['longitude'], df['latitude'])\n",
    "        \n",
    "        # Create GeoDataFrame\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            df, \n",
    "            geometry=geometry, \n",
    "            crs=\"EPSG:4326\"\n",
    "        )\n",
    "        # Convert CRS to UTM for accurate distance\n",
    "        utm_crs = gdf.estimate_utm_crs()\n",
    "        gdf = gdf.to_crs(utm_crs).copy()\n",
    "        geo_dataframes[name] = gdf\n",
    "        print(f\"Converted {name} to GeoDataFrame with {len(gdf)} points\")\n",
    "    \n",
    "    return geo_dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a3553c00-0963-499f-839d-c6a547910b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted gdf2015 to GeoDataFrame with 1237600 points\n",
      "Converted gdf2016 to GeoDataFrame with 1234221 points\n",
      "Converted gdf2017 to GeoDataFrame with 1227495 points\n",
      "Converted gdf2018 to GeoDataFrame with 1227495 points\n",
      "Converted gdf2019 to GeoDataFrame with 1227495 points\n",
      "Converted gdf2020 to GeoDataFrame with 1230858 points\n",
      "Converted gdf2021 to GeoDataFrame with 1227495 points\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    'gdf2015': df2015,\n",
    "    'gdf2016': df2016,\n",
    "    'gdf2017': df2017,\n",
    "    'gdf2018': df2018,\n",
    "    'gdf2019': df2019,\n",
    "    'gdf2020': df2020,\n",
    "    'gdf2021': df2021\n",
    "}\n",
    "\n",
    "# Convert all to GeoDataFrames\n",
    "geo_dataframes = convert_to_geodataframes(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "87c850cf-8d2c-4a0b-b176-2d29edf02246",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2016 = geo_dataframes['gdf2016']\n",
    "gdf2017 = geo_dataframes['gdf2017']\n",
    "gdf2018 = geo_dataframes['gdf2018']\n",
    "gdf2019 = geo_dataframes['gdf2019']\n",
    "gdf2020 = geo_dataframes['gdf2020']\n",
    "gdf2021 = geo_dataframes['gdf2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "881ca02e-c0b4-45c4-ae33-65ac5347e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_gdf = gpd.read_file(os.path.join(path, 'fires_clean.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b98957-9237-4a08-a016-5c086e0b4d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_since_2005 = fire_gdf[fire_gdf['ALARM_DATE']>='2005-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c422ed-23cf-48df-b489-9ad060637f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2 = fires_since_2005.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca7656-6df9-46f0-aece-38be95d00b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime\n",
    "gdf1['date_dt'] = pd.to_datetime(gdf1['date'])\n",
    "gdf2['date_dt'] = pd.to_datetime(gdf2['ALARM_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d77eee-028f-4dda-a139-181584502f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create buffered geometries (8000m buffer)\n",
    "gdf1['buffered_geom'] = gdf1.geometry.buffer(8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c5288a2e-882d-4b8a-af2d-ec59aeab974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wildfire_analysis(gdf1, gdf2, lat_col='latitude', lon_col='longitude'):\n",
    "    \"\"\"\n",
    "    Wildfire historical analysis with:\n",
    "    1. Pre-filtering of fire data by date range\n",
    "    2. Vectorized operations wherever possible\n",
    "    3. Parallel processing of coordinate groups\n",
    "    \n",
    "    Args:\n",
    "        gdf1: Primary GeoDataFrame (climate data with point coordinates)\n",
    "        gdf2: Secondary GeoDataFrame (fire data)\n",
    "        lat_col: Latitude column in climate_gdf\n",
    "        lon_col: Longitude column in climate_gdf\n",
    "        \n",
    "    Returns:\n",
    "        GeoDataFrame with four new columns:\n",
    "        - active_fire (bool)\n",
    "        - active_fire_acres (float)\n",
    "        - fire_past_5yrs (bool)\n",
    "        - fires_past_10yrs_count (int)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Build spatial index for fire data\n",
    "    print(\"Building spatial index...\")\n",
    "    fire_idx = index.Index()\n",
    "    fire_records = []  # Store fire records with their bounds and dates\n",
    "    \n",
    "    # Pre-compute bounds and store fire records\n",
    "    for i, (_, row) in enumerate(gdf2.iterrows()):\n",
    "        bounds = row.geometry.bounds\n",
    "        fire_idx.insert(i, bounds)\n",
    "        fire_records.append({\n",
    "            'bounds': bounds,\n",
    "            'geometry': row.geometry,\n",
    "            'acres': row['GIS_ACRES']\n",
    "        })\n",
    "    \n",
    "    # Initialize result columns with desired data types\n",
    "    gdf1['active_fire'] = False\n",
    "    gdf1['active_fire_acres'] = 0.0\n",
    "    gdf1['fire_past_5yrs'] = False\n",
    "    gdf1['fires_past_10yrs_count'] = 0\n",
    "    \n",
    "    # Group by coordinates and process in parallel\n",
    "    print(\"Processing coordinate groups...\")\n",
    "    coord_groups = gdf1.groupby([lat_col, lon_col])\n",
    "    \n",
    "    # Process each unique location\n",
    "    for (lat, lon), group_df in tqdm(coord_groups, desc=\"Processing locations\"):\n",
    "        # Get representative buffered geometry for this location\n",
    "        buffered_geom = group_df['buffered_geom'].iloc[0]\n",
    "        \n",
    "        # Find potentially intersecting fires using spatial index\n",
    "        possible_matches = list(fire_idx.intersection(buffered_geom.bounds))\n",
    "        if not possible_matches:\n",
    "            continue\n",
    "            \n",
    "        # Process each date at this location\n",
    "        for _, row in group_df.iterrows():\n",
    "            current_date = row['date_dt']\n",
    "            date_5yr = current_date - timedelta(days=5*365)\n",
    "            date_10yr = current_date - timedelta(days=10*365)\n",
    "            \n",
    "            # Initialize counters\n",
    "            active_fire = False\n",
    "            active_acres = 0.0\n",
    "            fire_5yr = False\n",
    "            fire_count_10yr = 0\n",
    "            \n",
    "            # Check each potential fire match\n",
    "            for match_idx in possible_matches:\n",
    "                fire_record = fire_records[match_idx]\n",
    "                \n",
    "                # Skip if fire date is outside our date range\n",
    "                if fire_record['date'] > current_date or fire_record['date'] < date_10yr:\n",
    "                    continue\n",
    "                    \n",
    "                # Check spatial intersection\n",
    "                if not buffered_geom.intersects(fire_record['geometry']):\n",
    "                    continue\n",
    "                    \n",
    "                # Check for active fire (same date)\n",
    "                if fire_record['date'] == current_date:\n",
    "                    active_fire = True\n",
    "                    active_acres = max(active_acres, fire_record['acres'])\n",
    "                \n",
    "                # Count for 10-year window\n",
    "                fire_count_10yr += 1\n",
    "                \n",
    "                # Check for 5-year window\n",
    "                if fire_record['date'] >= date_5yr:\n",
    "                    fire_5yr = True\n",
    "            \n",
    "            # Update results\n",
    "            gdf1.loc[row.name, 'active_fire'] = active_fire\n",
    "            gdf1.loc[row.name, 'active_fire_acres'] = active_acres\n",
    "            gdf1.loc[row.name, 'fire_past_5yrs'] = fire_5yr\n",
    "            gdf1.loc[row.name, 'fires_past_10yrs_count'] = fire_count_10yr\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    # gdf1.drop(columns=['buffered_geom'], inplace=True)\n",
    "    \n",
    "    return gdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ce5de9e3-0459-4874-bc7e-ed5121822cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimized spatial index...\n",
      "Processing coordinate groups...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████| 3363/3363 [28:48<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "gdf_16_proc = wildfire_analysis(gdf1=gdf2016, gdf2=gdf2, lat_col='latitude', lon_col='longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8b0237f9-5171-400c-9683-378f301661de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimized spatial index...\n",
      "Processing coordinate groups...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|███████████████| 3363/3363 [1:43:50<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimized spatial index...\n",
      "Processing coordinate groups...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████| 3363/3363 [56:42<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimized spatial index...\n",
      "Processing coordinate groups...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████| 3363/3363 [38:25<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimized spatial index...\n",
      "Processing coordinate groups...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████| 3363/3363 [37:39<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimized spatial index...\n",
      "Processing coordinate groups...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████| 3363/3363 [32:18<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "gdf_21_proc = optimized_wildfire_analysis(gdf1=gdf2021, gdf2=gdf2, lat_col='latitude', lon_col='longitude')\n",
    "gdf_21_csv = gdf_21_proc.drop(columns=['geometry'])\n",
    "gdf_21_csv.to_csv(os.path.join(path, 'fire_features_2021.csv'))\n",
    "\n",
    "gdf_20_proc = optimized_wildfire_analysis(gdf1=gdf2020, gdf2=gdf2, lat_col='latitude', lon_col='longitude')\n",
    "gdf_20_csv = gdf_20_proc.drop(columns=['geometry'])\n",
    "gdf_20_csv.to_csv(os.path.join(path, 'fire_features_2020.csv'))\n",
    "\n",
    "gdf_19_proc = optimized_wildfire_analysis(gdf1=gdf2019, gdf2=gdf2, lat_col='latitude', lon_col='longitude')\n",
    "gdf_19_csv = gdf_19_proc.drop(columns=['geometry'])\n",
    "gdf_19_csv.to_csv(os.path.join(path, 'fire_features_2019.csv'))\n",
    "\n",
    "gdf_18_proc = optimized_wildfire_analysis(gdf1=gdf2018, gdf2=gdf2, lat_col='latitude', lon_col='longitude')\n",
    "gdf_18_csv = gdf_18_proc.drop(columns=['geometry'])\n",
    "gdf_18_csv.to_csv(os.path.join(path, 'fire_features_2018.csv'))\n",
    "\n",
    "gdf_17_proc = optimized_wildfire_analysis(gdf1=gdf2017, gdf2=gdf2, lat_col='latitude', lon_col='longitude')\n",
    "gdf_17_csv = gdf_17_proc.drop(columns=['geometry'])\n",
    "gdf_17_csv.to_csv(os.path.join(path, 'fire_features_2017.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f2fbc137-cf89-4e0e-96d5-ad1b035193e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1234221 entries, 0 to 1247799\n",
      "Data columns (total 21 columns):\n",
      " #   Column                             Non-Null Count    Dtype  \n",
      "---  ------                             --------------    -----  \n",
      " 0   date                               1234221 non-null  object \n",
      " 1   longitude                          1234221 non-null  float64\n",
      " 2   latitude                           1234221 non-null  float64\n",
      " 3   temperature_2m                     1234221 non-null  float64\n",
      " 4   temperature_2m_max                 1234221 non-null  float64\n",
      " 5   total_precipitation_sum            1234221 non-null  float64\n",
      " 6   dewpoint_temperature_2m            1234221 non-null  float64\n",
      " 7   u_component_of_wind_10m            1234221 non-null  float64\n",
      " 8   v_component_of_wind_10m            1234221 non-null  float64\n",
      " 9   volumetric_soil_water_layer_1      1234221 non-null  float64\n",
      " 10  surface_net_solar_radiation_sum    1234221 non-null  float64\n",
      " 11  surface_net_thermal_radiation_sum  1234221 non-null  float64\n",
      " 12  surface_sensible_heat_flux_sum     1234221 non-null  float64\n",
      " 13  potential_evaporation_sum          1234221 non-null  float64\n",
      " 14  total_evaporation_sum              1234221 non-null  float64\n",
      " 15  leaf_area_index_high_vegetation    1234221 non-null  float64\n",
      " 16  leaf_area_index_low_vegetation     1234221 non-null  float64\n",
      " 17  active_fire                        1234221 non-null  bool   \n",
      " 18  active_fire_acres                  1234221 non-null  float64\n",
      " 19  fire_past_5yrs                     1234221 non-null  bool   \n",
      " 20  fires_past_10yrs_count             1234221 non-null  int64  \n",
      "dtypes: bool(2), float64(17), int64(1), object(1)\n",
      "memory usage: 190.7+ MB\n"
     ]
    }
   ],
   "source": [
    "gdf_csv = gdf_16_proc.drop(columns=['geometry'])\n",
    "gdf_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69223ade-b325-40e6-9695-a6550b3162d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdf_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gdf_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive_fire\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39msort_values()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdf_csv' is not defined"
     ]
    }
   ],
   "source": [
    "gdf_csv['active_fire'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df864e8-f547-49f8-8ba2-8aca46ba8669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
